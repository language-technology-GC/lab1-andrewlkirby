{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import gzip\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#open news data:\n",
    "#http://data.statmt.org/news-crawl/en/\n",
    "#2007 data\n",
    "input = gzip.GzipFile(\"C:/Users/Bertold/Documents/CUNY/Fall 2020/Language Technology/lab1/news.2007.en.shuffled.deduped.gz\", 'rb')\n",
    "s = input.read()\n",
    "input.close()\n",
    "\n",
    "output = open(\"text1.txt\", 'wb')\n",
    "output.write(s)\n",
    "output.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('text1.txt', encoding = 'utf-8') as fin, open('tokens.txt','w', encoding = 'utf-8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = word_tokenize(line)\n",
    "        print(' '.join(tokens), end='\\n', file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>car</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>car</td>\n",
       "      <td>6.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>television</td>\n",
       "      <td>radio</td>\n",
       "      <td>6.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>noon</td>\n",
       "      <td>string</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>chord</td>\n",
       "      <td>smile</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>professor</td>\n",
       "      <td>cucumber</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>king</td>\n",
       "      <td>cabbage</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             w1        w2  score\n",
       "0         tiger       cat   7.35\n",
       "1         tiger     tiger  10.00\n",
       "2         plane       car   5.77\n",
       "3         train       car   6.31\n",
       "4    television     radio   6.77\n",
       "..          ...       ...    ...\n",
       "198     rooster    voyage   0.62\n",
       "199        noon    string   0.54\n",
       "200       chord     smile   0.54\n",
       "201   professor  cucumber   0.31\n",
       "202        king   cabbage   0.23\n",
       "\n",
       "[203 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Bertold\\Documents\\CUNY\\Fall 2020\\Language Technology\\lab1\\data\\ws353.tsv\", sep='\\t', names=[\"w1\", \"w2\", \"score\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tiger</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tiger</td>\n",
       "      <td>tiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>television</td>\n",
       "      <td>radio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>rooster</td>\n",
       "      <td>voyage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>noon</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>chord</td>\n",
       "      <td>smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>professor</td>\n",
       "      <td>cucumber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>king</td>\n",
       "      <td>cabbage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>203 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             w1        w2\n",
       "0         tiger       cat\n",
       "1         tiger     tiger\n",
       "2         plane       car\n",
       "3         train       car\n",
       "4    television     radio\n",
       "..          ...       ...\n",
       "198     rooster    voyage\n",
       "199        noon    string\n",
       "200       chord     smile\n",
       "201   professor  cucumber\n",
       "202        king   cabbage\n",
       "\n",
       "[203 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ws353_twocol.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 483 words tracked\n",
      "INFO: 204 pairs tracked\n",
      "Traceback (most recent call last):\n",
      "  File \"ppmi.py\", line 107, in <module>\n",
      "    main(parser.parse_args())\n",
      "  File \"ppmi.py\", line 43, in main\n",
      "    for line in source:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 1579: character maps to <undefined>\n"
     ]
    }
   ],
   "source": [
    "#PPMI\n",
    "!python ppmi.py --results_path results.tsv --pairs_path ws353_twocol.tsv --tok_path tokens.txt\n",
    "#I got the below error which I assume is an encoding issue -- I made everything utf-8, but still got it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO: 483 words tracked\n",
    "INFO: 204 pairs tracked\n",
    "Traceback (most recent call last):\n",
    "  File \"ppmi.py\", line 107, in <module>\n",
    "    main(parser.parse_args())\n",
    "  File \"ppmi.py\", line 43, in main\n",
    "    for line in source:\n",
    "  File \"C:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
    "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
    "UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 1579: character maps to <undefined>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: PROGRESS: at sentence #10000, processed 237027 words, keeping 29151 word types\n",
      "INFO: PROGRESS: at sentence #20000, processed 472037 words, keeping 43538 word types\n",
      "INFO: PROGRESS: at sentence #30000, processed 706419 words, keeping 54732 word types\n",
      "INFO: PROGRESS: at sentence #40000, processed 941504 words, keeping 64093 word types\n",
      "INFO: collected 69478 word types from a corpus of 1088062 raw words and 46179 sentences\n",
      "INFO: Loading a fresh vocabulary\n",
      "INFO: effective_min_count=5 retains 14822 unique words (21% of original 69478, drops 54656)\n",
      "INFO: effective_min_count=5 leaves 1005892 word corpus (92% of original 1088062, drops 82170)\n",
      "INFO: deleting the raw counts dictionary of 69478 items\n",
      "INFO: sample=0.001 downsamples 39 most-common words\n",
      "INFO: downsampling leaves estimated 744704 word corpus (74.0% of prior 1005892)\n",
      "INFO: estimated required memory for 14822 words and 100 dimensions: 19268600 bytes\n",
      "INFO: resetting layer weights\n",
      "INFO: training model with 4 workers on 14822 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 1 : training on 1088062 raw words (744527 effective words) took 1.0s, 773955 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 2 : training on 1088062 raw words (744009 effective words) took 0.9s, 795857 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 3 : training on 1088062 raw words (744944 effective words) took 0.9s, 815254 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 4 : training on 1088062 raw words (744606 effective words) took 1.0s, 752338 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 5 : training on 1088062 raw words (744778 effective words) took 0.9s, 824737 effective words/s\n",
      "INFO: training on a 5440310 raw words (3722864 effective words) took 4.7s, 789730 effective words/s\n",
      "Traceback (most recent call last):\n",
      "  File \"word2vec.py\", line 65, in <module>\n",
      "    main(parser.parse_args())\n",
      "  File \"word2vec.py\", line 26, in main\n",
      "    for (x, y) in csv.reader(source, delimiter=\"\\t\"):\n",
      "ValueError: too many values to unpack (expected 2)\n"
     ]
    }
   ],
   "source": [
    "#Word2Vec\n",
    "!python word2vec.py --results_path resultsw2v.tsv --pairs_path ws353_twocol.tsv --tok_path tokens.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I got this after I ran it word2vec.py:\n",
    "INFO: EPOCH - 5 : training on 69577333 raw words (55858476 effective words) took 77.9s, 717503 effective words/s\n",
    "INFO: training on a 347886665 raw words (279289759 effective words) took 387.0s, 721703 effective words/s\n",
    "Traceback (most recent call last):\n",
    "  File \"word2vec.py\", line 65, in <module>\n",
    "    main(parser.parse_args())\n",
    "  File \"word2vec.py\", line 26, in main\n",
    "    for (x, y) in csv.reader(source, delimiter=\"\\t\"):\n",
    "ValueError: too many values to unpack (expected 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
